{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a022a53-6d82-42c5-ad62-c71ebba26333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84daab6a-9104-4f6c-9fb2-2fde2bb8e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_img=transforms.Compose([\n",
    "    transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "044c6d64-2b88-4011-8f60-20dfb762870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train=datasets.MNIST(root='./mnist_data', train=True, transform=transform_img)\n",
    "mnist_test=datasets.MNIST(root='./mnist_data', train=False, transform=transform_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1138a49-62b9-4010-8a39-d80a7a024bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.w=torch.randn(10,784)*0.01\n",
    "        self.b=torch.zeros(10,)\n",
    "        if torch.cuda.is_available():\n",
    "            self.w=self.w.to('cuda'); self.b=self.b.to('cuda')\n",
    "            \n",
    "    def softmax_function(self,X_train):\n",
    "        z= (self.w)@(X_train.T)+self.b.unsqueeze(1) \n",
    "        z_max= z.max(axis=0, keepdim=True).values\n",
    "        exp_z=torch.exp(z-z_max)\n",
    "        sum_exp_z=exp_z.sum(axis=0,keepdim=True)\n",
    "        softmax=(exp_z/sum_exp_z).T\n",
    "        return softmax\n",
    "            \n",
    "    def loss_function(self,X_train,y_train):\n",
    "        #using cross entropy loss\n",
    "        y_tg=(torch.arange(10).unsqueeze(0)==y_train.unsqueeze(1)).int()  \n",
    "        # torch.arange(10).unsqueeze(0)- creates a tensor of digits 0 to 9 ([0 1 2 3 4 5 6 7 8 9]) and unsqueezes its shape from [10] to [1,10]\n",
    "        # y_train.unsqueeze(1)- unsqueezes the y_train tensor from [128] to [128,1] \n",
    "        #\"==\" broadcasts the [1,10] and [128,1] tensor to [128,10]\n",
    "        # '.int()' bool function, that places 0 if condition not true and 1 otherwise\n",
    "        y_pred=self.softmax\n",
    "        y_pred=torch.clamp(y_pred, min=1e-7, max=1-1e-7)\n",
    "        CE_loss=-(y_tg*torch.log(y_pred)).sum(axis=1)\n",
    "        CE_loss=CE_loss.mean()\n",
    "        return CE_loss\n",
    "\n",
    "    def gradient_descent(self,X_train,y_train,lr):\n",
    "        y_tg=(torch.arange(10, device= y_train.device).unsqueeze(0)==y_train.unsqueeze(1)).int()\n",
    "        y_pred=self.softmax_function(X_train)\n",
    "        error= ((y_pred)-(y_tg))/len(X_train)\n",
    "        w_grad=error.T@X_train\n",
    "        b_grad=error.sum(axis=0)\n",
    "        self.w-=w_grad*lr\n",
    "        self.b-=b_grad*lr\n",
    "        return self.w,self.b\n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        y_pred=self.softmax_function(X_test)\n",
    "        pred_class=torch.argmax(y_pred, axis=1)\n",
    "        return pred_class\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ca1b1-baff-43df-8926-f066c7f1ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(mnist_train, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e9bbda7-f4ad-4db3-9a0d-48e110daa074",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "model=SoftmaxRegression()\n",
    "for _ in range(epochs):\n",
    "    for images,labels in train_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            X_train=images.to('cuda')\n",
    "            y_train=labels.to('cuda')\n",
    "        model.gradient_descent(X_train,y_train,lr=0.01)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac02864-3d63-43c6-9d21-8a4081cc2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for images,labels in mnist_test:\n",
    "    if torch.cuda.is_available():\n",
    "        X_test=images.to('cuda')\n",
    "    pred=model.predict(X_test).cpu()\n",
    "    correct=(pred==labels).sum().item()\n",
    "    count+=correct\n",
    "    df=pd.DataFrame({\n",
    "        \"predicted class\": model.predict(X_test).tolist(),\n",
    "        \"actual class\": labels.tolist()\n",
    "        })\n",
    "    print(df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "07f33b74-a7e2-4744-a7c2-ef6b1f68934e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the model correctly predicted 9204 / 10000\n",
      " the percentage accuracy is 92.04\n"
     ]
    }
   ],
   "source": [
    "print(f\" the model correctly predicted {count} / {len(mnist_test)}\")\n",
    "print(f\" the percentage accuracy is {(count/len(mnist_test))*100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ENV_1)",
   "language": "python",
   "name": "env_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
